{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d15295-1864-498e-aec7-3c942bee1f5b",
   "metadata": {},
   "source": [
    "Ensemble technique in machine learning involve combining multiple models to improve predctive performance. This is often acheived by averaging or combining the preddction of sevral models such as decsion tree,neural network or support vector machine.Ensemble methods aim to reduce overfitting increase robustness and enhance genralization by leveragining the diversity of the constituent models.Popular ensemble technique include bagging boostig,and stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc105c-6020-42d1-ae41-e2c9e0ccae67",
   "metadata": {},
   "source": [
    "Ensemble technique used in machine learning because they combine multiples models to improve predctive performance by aggregating the predction of multiple models ensemble method can often acheive better accuracy and genralization \n",
    "compared to indvidual models.They help to reduce overfitting increase stablity and handle noisy data effectively some popular ensemble techniques include bagging boosting and stacking overall ensemble techniques are variable tools for improving the robustness and accuracy of machine learningg models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977ff06-8e32-4ce1-ae39-e34740b123ad",
   "metadata": {},
   "source": [
    "Bagging shortt for bootstrap aggregating is a popular ensemble technique in machine learning.it involves traning multiple models independently on diffrent subsets of the traning data which are randomly sampled with replacement \n",
    "1. Bootstrap Sampling\n",
    "2. Model Traning\n",
    "3. Aggreating\n",
    "Bagging helps to reduce variance and overfitting by averaging the predctions of multiple models trained on slightly \n",
    "diffrent datsets.it can improve the overall performance and stablity of machine learning models,especilly when used \n",
    "with high-variance alogrthims like descion tree one popular begging algorthim is Random forest which uses an ensemble of decsion trees trained via bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc97ea9-b367-41c6-a402-80c9a773bc45",
   "metadata": {},
   "source": [
    "Boostingg is another ensemble technique used in machine learning which aims to sequentially improve the performance of a model by focussing on instance that were previsouly misclassfied.Unlike bagging where models are trained indpendently boosting sequentially builds a strong model by combining weak learners in a step-wise manner\n",
    "1. Sequential Traning\n",
    "2. Instance Weighting\n",
    "3. Sequential Improvement\n",
    "4. Combining predctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4135f2b-39da-4144-b72e-23dd30bff7ba",
   "metadata": {},
   "source": [
    "Using ensemble techniques in machine learniing offers sevral benfits:\n",
    "1. Improved Accuracy: Ensemble method often yield higher predctive accuracy compared to indvidual mpdels by leveraging the strength of multiple models and mitigating their weakness\n",
    "2. Robustness:Ensemble are more robust to noise and outliers in the data because they aggrregate predction form multiple models reducing the impact of indvidual errors'\n",
    "3. Reduced ovefitting:Ensemble technique help to redcue overfitting by combining models trained on diffrent subsets of the data or by penlizing complex "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322dea9f-3e2e-4a54-a541-3194339a939d",
   "metadata": {},
   "source": [
    "Ensemble techniques can often outperform indiviual models because they leverage the strength of multiple models to mitigate weakness and improve overall performance however whether an ensemble is better than an indvidual model the diversity among them and how they are combined in some case a single well-tuned model may perform comparably to an ensemble especiallyy if the dataset is small or the models are depends the diversity among them and how they are combined in some cases a single well- tuned model may perform comparably to an ensemble especially if the dataset is small or the models are already highly accurate on their own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7694ac-547a-4c4b-92f4-a6f6bc261bf0",
   "metadata": {},
   "source": [
    "A Condfidence interval (ci) calculator using bootstrap is a statitical tool that estimate the uncertanity around a  paramter such as a mean or medium by resampling the observed data with replacement here is genral outline how it works:\n",
    "1. Bootstrap Resampling\n",
    "2. Prameter Estimation\n",
    "3. Confidence interval calculation\n",
    "4. Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4a578-fb3d-4b59-aa41-b1b4d02a0829",
   "metadata": {},
   "source": [
    " Boostrap is a popular front-end framework for building responsive and mobile-first website.it simplfies the process of web website it simplfies the process of web development by provding pre-designed templates CSS styles and javaScript components that can be easily intergrated into web project\n",
    " 1. Setting up\n",
    " 2. Html structure\n",
    " 3. Css classes\n",
    " 4. Components\n",
    " 5. JavaScript\n",
    " 6. Customization\n",
    " 7. Testing and Optimizstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5a7df-d805-4c7f-b3fc-6fa39a9b5a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
